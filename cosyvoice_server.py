# -*- coding: utf-8 -*-
"""
Fun-CosyVoice3-0.5B-2512 æµå¼ TTS æœåŠ¡ç«¯
========================================
åŠŸèƒ½: æä¾›åŸºäº FastAPI çš„æµå¼è¯­éŸ³åˆæˆæœåŠ¡
æ”¯æŒ:
  - æµå¼éŸ³é¢‘è¾“å‡º (StreamingResponse)
  - Zero-shot éŸ³è‰²å…‹éš†
  - é¢„ç½®é»˜è®¤éŸ³è‰²
  - å¹¶å‘è¯·æ±‚å¤„ç†

ä½œè€…: å‡Œå° aibook.ren(AIå…¨ä¹¦)
æ—¥æœŸ: 2025-12
"""
import os
import sys
print(f"DEBUG SYSTARGV: {sys.argv}")
import argparse
import logging
import time
import numpy as np
from typing import Optional, Generator
from concurrent.futures import ThreadPoolExecutor
import threading
import torch
import torchaudio

# è®¾ç½®è·¯å¾„
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, SCRIPT_DIR)
sys.path.insert(0, os.path.join(SCRIPT_DIR, 'third_party', 'Matcha-TTS'))

from fastapi import FastAPI, Form, File, UploadFile, HTTPException
from fastapi.responses import StreamingResponse, JSONResponse
from fastapi.middleware.cors import CORSMiddleware
import uvicorn

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ============================================================================
# å¤šéŸ³è‰²é…ç½® (ç”¨æˆ·å¯ä¿®æ”¹æ­¤éƒ¨åˆ†)
# ============================================================================
# æ ¼å¼: {"id": "éŸ³è‰²ID", "file": "æ–‡ä»¶å", "prompt_text": "éŸ³é¢‘ä¸­è¯´çš„è¯"}
# æ–‡ä»¶æ”¾åœ¨ deploy/cosyvoice/asset/ ç›®å½•ä¸‹
# è¦æ±‚éŸ³é¢‘æ¸…æ™°ï¼ˆ5~15ç§’ä¸ºä½³ï¼Œä¸è¦è¿‡é•¿ï¼‰ï¼Œä¿å­˜ä¸ºwavæ ¼å¼ï¼Œé‡‡é›†ç‡16kHz,å•å£°é“ï¼Œå†…å®¹ä»»æ„ï¼Œä½†æ˜¯å’Œprompt_texté‡Œçš„å†…å®¹å®Œå…¨ä¸€è‡´ï¼Œå¿…é¡»ä¸€å­—ä¸å·®ï¼
# CosyVoice3 çš„ prompt_text å¿…é¡»ä»¥ "You are a helpful assistant.<|endofprompt|>" å¼€å¤´
# ============================================================================
VOICE_CONFIGS = [
    {
        "id": "default",  # é»˜è®¤éŸ³è‰²
        "file": "zero_shot_prompt.wav",  # asset/zero_shot_prompt.wav
        "prompt_text": "You are a helpful assistant.<|endofprompt|>å¸Œæœ›ä½ ä»¥åèƒ½å¤Ÿåšçš„æ¯”æˆ‘è¿˜å¥½å‘¦ã€‚"
    },
    # æ·»åŠ æ›´å¤šéŸ³è‰²ç¤ºä¾‹ (å–æ¶ˆæ³¨é‡Šå¹¶ä¿®æ”¹):
    {
        "id": "longyingcheng",
        "file": "longyingcheng_man.wav",
        "prompt_text": "You are a helpful assistant.<|endofprompt|>çœŸä¸å¥½æ„æ€ï¼Œä»å°è‡³ä»Šï¼Œä»–è¿˜ä»æ¥æ²¡æœ‰è¢«å“ªä¸€ä½å¼‚æ€§æœ‹å‹äº²å»è¿‡å‘¢ã€‚"
    },
    {
         "id": "longyingwan",
         "file": "longyingwan_woman.wav", 
         "prompt_text": "You are a helpful assistant.<|endofprompt|>æˆ‘ä»¬å°†ä¸ºå…¨çƒåŸå¸‚çš„å¯æŒç»­å‘å±•è´¡çŒ®åŠ›é‡ã€‚"
    },
    {
        "id": "longyingmu",
        "file": "longyingmu_woman.wav",
        "prompt_text": "You are a helpful assistant.<|endofprompt|>æ‚¨å¥½ï¼Œæˆ‘æ˜¯æ™ºèƒ½ç”µè¯åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºæ‚¨æœåŠ¡ã€‚è¯·é—®æ‚¨éœ€è¦å’¨è¯¢ä¸šåŠ¡é¢„çº¦åŠç†è¿˜æ˜¯æŸ¥è¯¢ä¿¡æ¯ï¼Ÿ"
    }
    {
        "id": "longshu",
        "file": "longshu.wav",
        "prompt_text": "You are a helpful assistant.<|endofprompt|>Technology has made it easier to learn new languagesã€‚é€šè¿‡appså’Œonline coursesï¼Œanyone can start learningä¸­æ–‡æˆ–è€…å…¶ä»–è¯­è¨€ã€‚"
    }
]
# ============================================================================

# å…¨å±€å˜é‡
cosyvoice = None
inference_lock = threading.Lock()

# å¤šéŸ³è‰²ç¼“å­˜: {voice_id: {"file": path, "prompt_text": text}}
voice_cache = {}
default_voice_id = "default"  # é»˜è®¤ä½¿ç”¨çš„éŸ³è‰²ID

# è¾“å‡ºé‡‡æ ·ç‡ (å¯é€šè¿‡ --output_sample_rate é…ç½®)
# é»˜è®¤ 16000 ä»¥å…¼å®¹å°æ™ºå¹³å°
output_sample_rate = 16000

# [æ³¨æ„] CosyVoice API ä¸æ”¯æŒä¼ å…¥ Tensorï¼Œå¿…é¡»ä¼ è·¯å¾„æˆ–æ–‡ä»¶å¯¹è±¡ï¼Œå› æ­¤ç§»é™¤ resampler_cache ä¼˜åŒ–


app = FastAPI(title="CosyVoice TTS Server", version="1.0.0")

# CORS é…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"]
)





def generate_audio_stream(
    text: str,
    voice_id: str = None,
    prompt_text: str = None,
    prompt_wav = None,
    stream: bool = True
) -> Generator[bytes, None, None]:
    """
    ç”Ÿæˆæµå¼éŸ³é¢‘æ•°æ®
    
    Args:
        text: è¦åˆæˆçš„æ–‡æœ¬
        voice_id: éŸ³è‰²ID (ä½¿ç”¨é¢„åŠ è½½çš„ç¼“å­˜éŸ³è‰²ï¼Œé›¶å»¶è¿Ÿ)
        prompt_text: è‡ªå®šä¹‰éŸ³è‰²çš„æç¤ºæ–‡æœ¬ (ä¸ prompt_wav é…åˆä½¿ç”¨)
        prompt_wav: è‡ªå®šä¹‰éŸ³è‰²çš„å‚è€ƒéŸ³é¢‘ (ä¸ prompt_text é…åˆä½¿ç”¨)
        stream: æ˜¯å¦æµå¼è¾“å‡º
    """
    global cosyvoice, voice_cache
    
    with inference_lock:
        try:
            # ç¡®å®šä½¿ç”¨å“ªä¸ªéŸ³è‰²
            spk_id = ""
            actual_prompt_text = prompt_text
            actual_prompt_wav = prompt_wav
            
            # ä¼˜å…ˆä½¿ç”¨ voice_id (é¢„ç¼“å­˜éŸ³è‰²)
            if voice_id and voice_id in voice_cache:
                spk_id = voice_id
                voice_info = voice_cache[voice_id]
                actual_prompt_text = voice_info["prompt_text"]
                actual_prompt_wav = voice_info["file"]
                logger.debug(f"âš¡ ä½¿ç”¨é¢„ç¼“å­˜éŸ³è‰²: {voice_id} (é›¶I/O/è®¡ç®—)")
            elif voice_id and voice_id not in voice_cache:
                logger.warning(f"éŸ³è‰² '{voice_id}' ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤éŸ³è‰²")
                if default_voice_id in voice_cache:
                    spk_id = default_voice_id
                    voice_info = voice_cache[default_voice_id]
                    actual_prompt_text = voice_info["prompt_text"]
                    actual_prompt_wav = voice_info["file"]
            elif prompt_text and prompt_wav:
                # ä½¿ç”¨è‡ªå®šä¹‰éŸ³è‰² (æ— ç¼“å­˜ï¼Œéœ€å®æ—¶è®¡ç®—)
                logger.debug("ä½¿ç”¨è‡ªå®šä¹‰éŸ³è‰² (å®æ—¶è®¡ç®—ç‰¹å¾)")
            else:
                # ä½¿ç”¨é»˜è®¤éŸ³è‰²
                if default_voice_id in voice_cache:
                    spk_id = default_voice_id
                    voice_info = voice_cache[default_voice_id]
                    actual_prompt_text = voice_info["prompt_text"]
                    actual_prompt_wav = voice_info["file"]
                    logger.debug(f"âš¡ ä½¿ç”¨é»˜è®¤éŸ³è‰²: {default_voice_id}")
                
            for result in cosyvoice.inference_zero_shot(
                text, 
                actual_prompt_text, 
                actual_prompt_wav,
                stream=stream,
                zero_shot_spk_id=spk_id
            ):
                audio_tensor = result['tts_speech']
                
                # [GPU é‡é‡‡æ ·] å¦‚æœè¾“å‡ºé‡‡æ ·ç‡ä¸æ¨¡å‹åŸç”Ÿä¸åŒï¼Œè¿›è¡Œé‡é‡‡æ ·
                if output_sample_rate != cosyvoice.sample_rate:
                    audio_tensor = torchaudio.functional.resample(
                        audio_tensor, 
                        orig_freq=cosyvoice.sample_rate, 
                        new_freq=output_sample_rate
                    )
                
                # [GPU ç‰ˆæœ¬] PCM 16bit è½¬æ¢
                # 1. GPU è¿›è¡Œä¹˜æ³• (* 32768)
                # 2. GPU è¿›è¡Œç±»å‹è½¬æ¢ (float -> int16)
                # 3. ä¼ è¾“ int16 (2 bytes) åˆ° CPU
                yield (audio_tensor * 32768).to(torch.int16).cpu().numpy().tobytes()
        except Exception as e:
            logger.error(f"TTS ç”Ÿæˆå¤±è´¥: {e}")
            raise


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    # import torch # å·²åœ¨å…¨å±€å¯¼å…¥
    
    gpu_info = {}
    if torch.cuda.is_available():
        gpu_info = {
            "gpu_name": torch.cuda.get_device_name(0),
            "gpu_memory_allocated": f"{torch.cuda.memory_allocated(0) / 1024**3:.2f}GB",
            "gpu_memory_cached": f"{torch.cuda.memory_reserved(0) / 1024**3:.2f}GB"
        }
    
    return JSONResponse({
        "status": "ok",
        "model": "Fun-CosyVoice3-0.5B-2512",
        "model_sample_rate": cosyvoice.sample_rate if cosyvoice else None,
        "output_sample_rate": output_sample_rate,
        "available_voices": list(voice_cache.keys()),
        "default_voice": default_voice_id,
        **gpu_info
    })


@app.post("/tts/stream")
async def tts_stream(
    text: str = Form(..., description="è¦åˆæˆçš„æ–‡æœ¬"),
    voice_id: Optional[str] = Form(default=None, description="éŸ³è‰²ID (ä½¿ç”¨é¢„åŠ è½½çš„éŸ³è‰²ï¼Œé›¶å»¶è¿Ÿ)"),
    prompt_text: Optional[str] = Form(default=None, description="è‡ªå®šä¹‰éŸ³è‰²çš„æç¤ºæ–‡æœ¬"),
    prompt_wav: Optional[UploadFile] = File(default=None, description="è‡ªå®šä¹‰éŸ³è‰²çš„å‚è€ƒéŸ³é¢‘")
):
    """
    æµå¼ TTS æ¥å£
    
    å‚æ•°ä¼˜å…ˆçº§:
    1. voice_id: ä½¿ç”¨é¢„åŠ è½½çš„éŸ³è‰² (æ¨èï¼Œé›¶å»¶è¿Ÿ)
    2. prompt_text + prompt_wav: è‡ªå®šä¹‰éŸ³è‰² (éœ€å®æ—¶è®¡ç®—ç‰¹å¾)
    3. éƒ½ä¸ä¼ : ä½¿ç”¨é»˜è®¤éŸ³è‰²
    
    è¿”å›: æµå¼ PCM éŸ³é¢‘æ•°æ® (é‡‡æ ·ç‡ç”± --output_sample_rate æ§åˆ¶, 16bit, Mono)
    """
    if not text or len(text.strip()) == 0:
        raise HTTPException(status_code=400, detail="æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
    
    # å¤„ç†è‡ªå®šä¹‰éŸ³è‰²çš„å‚è€ƒéŸ³é¢‘
    prompt_wav_data = None
    if prompt_wav is not None:
        prompt_wav_data = prompt_wav.file
    
    # è®°å½•æ—¥å¿—
    if voice_id:
        logger.info(f"TTS è¯·æ±‚: text='{text[:50]}...', voice_id='{voice_id}'")
    elif prompt_text:
        logger.info(f"TTS è¯·æ±‚: text='{text[:50]}...', prompt_text='{prompt_text[:30]}...' (è‡ªå®šä¹‰éŸ³è‰²)")
    else:
        logger.info(f"TTS è¯·æ±‚: text='{text[:50]}...', voice_id='default'")
    
    start_time = time.time()
    
    def stream_generator():
        first_chunk = True
        total_bytes = 0
        for chunk in generate_audio_stream(
            text, 
            voice_id=voice_id,
            prompt_text=prompt_text, 
            prompt_wav=prompt_wav_data, 
            stream=True
        ):
            if first_chunk:
                logger.info(f"âš¡ é¦–å¸§å»¶è¿Ÿ: {(time.time() - start_time) * 1000:.0f}ms")
                first_chunk = False
            total_bytes += len(chunk)
            yield chunk
        logger.info(f"âœ… TTS å®Œæˆ: æ€»è€—æ—¶ {(time.time() - start_time) * 1000:.0f}ms, æ•°æ®é‡ {total_bytes / 1024:.1f}KB")
    
    return StreamingResponse(
        stream_generator(),
        media_type="application/octet-stream",
        headers={
            "X-Sample-Rate": str(output_sample_rate),
            "X-Channels": "1",
            "X-Bits": "16"
        }
    )


@app.post("/tts/zero_shot")
async def tts_zero_shot(
    text: str = Form(..., description="è¦åˆæˆçš„æ–‡æœ¬"),
    prompt_text: str = Form(..., description="å‚è€ƒéŸ³é¢‘å¯¹åº”çš„æ–‡æœ¬"),
    prompt_wav: UploadFile = File(..., description="å‚è€ƒéŸ³é¢‘æ–‡ä»¶ (WAV, 16kHz)")
):
    """
    Zero-shot éŸ³è‰²å…‹éš†æ¥å£
    
    è¿”å›: æµå¼ PCM éŸ³é¢‘æ•°æ®
    """
    if not text or len(text.strip()) == 0:
        raise HTTPException(status_code=400, detail="æ–‡æœ¬ä¸èƒ½ä¸ºç©º")
    if not prompt_text or len(prompt_text.strip()) == 0:
        raise HTTPException(status_code=400, detail="æç¤ºæ–‡æœ¬ä¸èƒ½ä¸ºç©º")
    
    try:
        # ç›´æ¥ä¼ å…¥æ–‡ä»¶å¯¹è±¡ (SpooledTemporaryFile)
        prompt_wav_data = prompt_wav.file
    except Exception as e:
        raise HTTPException(status_code=400, detail=f"éŸ³é¢‘æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
    
    logger.info(f"Zero-shot TTS: text='{text[:50]}...', prompt='{prompt_text[:30]}...'")
    
    def stream_generator():
        for chunk in generate_audio_stream(text, prompt_text, prompt_wav_data, stream=True):
            yield chunk
    
    return StreamingResponse(
        stream_generator(),
        media_type="application/octet-stream",
        headers={
            "X-Sample-Rate": str(cosyvoice.sample_rate),
            "X-Channels": "1",
            "X-Bits": "16"
        }
    )


def load_model(model_dir: str, device: str = "cuda", fp16: bool = False, use_vllm: bool = False):
    """åŠ è½½ CosyVoice æ¨¡å‹"""
    global cosyvoice, voice_cache
    
    from cosyvoice.cli.cosyvoice import AutoModel
    
    logger.info(f"æ­£åœ¨åŠ è½½æ¨¡å‹: {model_dir}")
    logger.info(f"è®¾å¤‡: {device}, FP16: {fp16}, vLLMåŠ é€Ÿ: {use_vllm}")
    
    if use_vllm:
        try:
            import vllm
        except ImportError:
            logger.error("å¯ç”¨ vLLM å¤±è´¥: æœªæ‰¾åˆ° vllm åº“ã€‚è¯·å…ˆå®‰è£…: pip install vllm==0.9.0")
            sys.exit(1)
            
    start_time = time.time()
    try:
        # load_vllm å‚æ•°ä¼šè‡ªåŠ¨è§¦å‘ CosyVoice2/3 æ¨¡å‹çš„ vLLM åŠ è½½é€»è¾‘
        # æ³¨æ„: åº“å†…éƒ¨é»˜è®¤ gpu_memory_utilization=0.2 (é€‚é… 24G æ˜¾å­˜)
        cosyvoice = AutoModel(model_dir=model_dir, fp16=fp16, load_vllm=use_vllm)
    except TypeError as e:
        if "load_vllm" in str(e):
             logger.error("å½“å‰ CosyVoice ç‰ˆæœ¬ä¼¼ä¹ä¸æ”¯æŒ vLLMï¼Œè¯·ç¡®ä¿ä½¿ç”¨æœ€æ–°ä»£ç ")
        raise e
        
    logger.info(f"æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {time.time() - start_time:.1f}s")
    logger.info(f"æ¨¡å‹é‡‡æ ·ç‡: {cosyvoice.sample_rate}Hz, è¾“å‡ºé‡‡æ ·ç‡: {output_sample_rate}Hz")
    
    # ========== åŠ è½½å¤šéŸ³è‰²é…ç½® ==========
    asset_dir = os.path.join(SCRIPT_DIR, "asset")
    official_asset_dir = os.path.join(SCRIPT_DIR, "official", "asset")
    
    logger.info(f"âš¡ æ­£åœ¨åŠ è½½ {len(VOICE_CONFIGS)} ä¸ªéŸ³è‰²é…ç½®...")
    
    for voice_config in VOICE_CONFIGS:
        voice_id = voice_config["id"]
        voice_file = voice_config["file"]
        prompt_text = voice_config["prompt_text"]
        
        # æŸ¥æ‰¾éŸ³é¢‘æ–‡ä»¶
        voice_path = os.path.join(asset_dir, voice_file)
        if not os.path.exists(voice_path):
            # å°è¯•ä»å®˜æ–¹ç›®å½•æŸ¥æ‰¾
            voice_path = os.path.join(official_asset_dir, voice_file)
        
        if not os.path.exists(voice_path):
            logger.warning(f"âŒ éŸ³è‰² '{voice_id}' çš„æ–‡ä»¶æœªæ‰¾åˆ°: {voice_file}")
            continue
        
        try:
            # ç¼“å­˜éŸ³è‰²ç‰¹å¾
            cosyvoice.add_zero_shot_spk(prompt_text, voice_path, voice_id)
            
            # ä¿å­˜åˆ° voice_cache
            voice_cache[voice_id] = {
                "file": voice_path,
                "prompt_text": prompt_text
            }
            logger.info(f"âœ… éŸ³è‰² '{voice_id}' åŠ è½½æˆåŠŸ: {voice_file}")
        except Exception as e:
            logger.warning(f"âŒ éŸ³è‰² '{voice_id}' åŠ è½½å¤±è´¥: {e}")
    
    logger.info(f"âš¡ éŸ³è‰²åŠ è½½å®Œæˆï¼Œå…± {len(voice_cache)} ä¸ªå¯ç”¨éŸ³è‰²: {list(voice_cache.keys())}")
    
    # é¢„çƒ­æ¨ç† (ä½¿ç”¨ç¬¬ä¸€ä¸ªå¯ç”¨éŸ³è‰²)
    first_voice_path = None
    if voice_cache:
        first_voice_id = list(voice_cache.keys())[0]
        first_voice_path = voice_cache[first_voice_id]["file"]
    warmup_model(first_voice_path, first_voice_id if voice_cache else None)
    
    return cosyvoice


def warmup_model(prompt_wav_path: str = None, voice_id: str = None):
    """é¢„çƒ­æ¨¡å‹ï¼Œå‡å°‘é¦–æ¬¡è¯·æ±‚å»¶è¿Ÿ"""
    global cosyvoice
    
    if cosyvoice is None:
        return
    
    logger.info("ğŸ”¥ æ­£åœ¨é¢„çƒ­æ¨¡å‹...")
    start_time = time.time()
    
    warmup_text = "é¢„çƒ­æµ‹è¯•"
    warmup_prompt_text = "é¢„çƒ­"
    
    # å¦‚æœæœ‰å‚è€ƒéŸ³é¢‘ï¼Œä½¿ç”¨ zero-shot é¢„çƒ­
    if prompt_wav_path and os.path.exists(prompt_wav_path):
        try:
            # ä½¿ç”¨æŒ‡å®šçš„ voice_id è¿›è¡Œé¢„çƒ­
            spk_id = voice_id if voice_id else "default"
            for _ in cosyvoice.inference_zero_shot(
                warmup_text, 
                warmup_prompt_text, 
                prompt_wav_path,
                stream=False,
                zero_shot_spk_id=spk_id
            ):
                pass
            logger.info(f"âœ… æ¨¡å‹é¢„çƒ­å®Œæˆï¼Œè€—æ—¶: {time.time() - start_time:.1f}s")
        except Exception as e:
            logger.warning(f"é¢„çƒ­å¤±è´¥ (ä¸å½±å“æ­£å¸¸ä½¿ç”¨): {e}")
    else:
        logger.info("â­ è·³è¿‡é¢„çƒ­ (æ— å‚è€ƒéŸ³é¢‘)")


def main():
    global output_sample_rate
    
    parser = argparse.ArgumentParser(description="CosyVoice TTS Server")
    parser.add_argument("--host", type=str, default="0.0.0.0", help="ç›‘å¬åœ°å€")
    parser.add_argument("--port", type=int, default=10096, help="ç›‘å¬ç«¯å£")
    parser.add_argument(
        "--model_dir", 
        type=str, 
        default="models/Fun-CosyVoice3-0.5B",
        help="æ¨¡å‹ç›®å½•è·¯å¾„"
    )
    parser.add_argument("--device", type=str, default="cuda", help="è¿è¡Œè®¾å¤‡: cuda æˆ– cpu")
    parser.add_argument("--fp16", action="store_true", help="ä½¿ç”¨ FP16 æ¨ç† (èŠ‚çœæ˜¾å­˜)")
    parser.add_argument("--use_vllm", action="store_true", help="[ä¼˜åŒ–] ä½¿ç”¨ vLLM åŠ é€Ÿæ¨ç† (éœ€ pip install vllm)")
    parser.add_argument(
        "--output_sample_rate", 
        type=int, 
        default=16000, 
        choices=[16000, 24000],
        help="è¾“å‡ºé‡‡æ ·ç‡: 16000 (å…¼å®¹å°æ™ºå¹³å°) æˆ– 24000 (åŸç”Ÿé«˜è´¨é‡)"
    )
    args = parser.parse_args()
    
    # è®¾ç½®è¾“å‡ºé‡‡æ ·ç‡
    output_sample_rate = args.output_sample_rate
    
    # å¤„ç†ç›¸å¯¹è·¯å¾„
    if not os.path.isabs(args.model_dir):
        args.model_dir = os.path.join(SCRIPT_DIR, args.model_dir)
    
    # åŠ è½½æ¨¡å‹
    load_model(args.model_dir, args.device, args.fp16, args.use_vllm)
    
    # å¯åŠ¨æœåŠ¡
    logger.info(f"æœåŠ¡å·²å¯åŠ¨: http://{args.host}:{args.port}")
    logger.info(f"å¥åº·æ£€æŸ¥: http://{args.host}:{args.port}/health")
    logger.info(f"TTS æ¥å£: POST http://{args.host}:{args.port}/tts/stream")
    logger.info(f"ğŸ“¢ è¾“å‡ºé‡‡æ ·ç‡: {output_sample_rate}Hz (æ¨¡å‹åŸç”Ÿ: 24000Hz)")
    
    uvicorn.run(app, host=args.host, port=args.port)


if __name__ == "__main__":
    main()
